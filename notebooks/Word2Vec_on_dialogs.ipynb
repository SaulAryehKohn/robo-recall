{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import spacy\n",
    "plt.style.use('ggplot')\n",
    "from spacy import displacy\n",
    "import numpy as np\n",
    "import itertools\n",
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "stop_words = stopwords.words('english')\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/dialogues_text.txt') as file:\n",
    "    dialogs = [line.rstrip('\\n') for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogs_sp = [dlg.split(\"__eou__\")[:-1] for dlg in dialogs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "longer_dialogs = [dlg for dlg in dialogs_sp if len(dlg)>=10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = gensim.models.KeyedVectors.load_word2vec_format('../data/GoogleNews-vectors-negative300.bin.gz', binary=True)  # C binary format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "longer_dialogs_nlpd_cleaned = []\n",
    "for i,dlg in enumerate(longer_dialogs):\n",
    "    tmp_dialog_stor = []\n",
    "    for j,sentence in enumerate(dlg):\n",
    "        sentarr = [w.lower() for w in sentence.split() if not w.lower() in stop_words and not len(w)<4]\n",
    "        nlp_sentarr = nlp(' '.join(sentarr))\n",
    "        nouns_sentarr = [tk.lemma_ for tk in nlp_sentarr if tk.pos_ in ['NOUN','PROPN']]\n",
    "        tmp_dialog_stor.append(nouns_sentarr)\n",
    "    longer_dialogs_nlpd_cleaned.append(tmp_dialog_stor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "longer_dialogs_nlpd_cleaned_toText = []\n",
    "\n",
    "for dlg in longer_dialogs_nlpd_cleaned:\n",
    "    tmp_dialog_stor = []\n",
    "    for tokenlist in dlg:\n",
    "        if len(tokenlist)==0:\n",
    "            continue\n",
    "        tmp_dialog_stor.append(tokenlist)\n",
    "    longer_dialogs_nlpd_cleaned_toText.append(tmp_dialog_stor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import csv\n",
    "with open(\"output.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(longer_dialogs_nlpd_cleaned_toText)\n",
    "\"\"\"\n",
    "pickle.dump(longer_dialogs_nlpd_cleaned_toText,open('longer_nlpd_cleaned_lemmatized_array.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "longer_dialogs_nlpd_cleaned_2 = pickle.load( open( \"longer_nlpd_cleaned_lemmatized_array.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['story'], ['opera', 'scene'], ['love', 'name'], ['what', 'know', 'help'], ['notice', 'laura'], ['thing', 'time'], ['opera'], ['carmen', 'mind'], ['wife', 'grave', 'hand', 'someone'], ['actress', 'voice'], ['applause', 'time'], ['applause', 'show'], ['performance', 'lighting', 'music'], ['thing', 'phantom', 'show']]\n",
      "0 [('Ohmigosh', 0.700766921043396), ('sanctuary_DellaBianca', 0.6650032997131348), ('vent_Gespass', 0.6648831367492676), ('spoons_clanking', 0.6593939065933228), ('BLATHER_1', 0.6542034149169922)]\n",
      "==========\n",
      "[['mother', 'video', 'game'], ['what'], ['hero', 'warrior', 'fight', 'guy', 'treasure'], ['guy'], ['one', 'monster', 'spider'], ['treasure'], ['dungeon', 'castle'], ['school', 'today']]\n",
      "1 [('Crave_Online_Did', 0.6122910380363464), ('kid', 0.6049538254737854), (\"AJ'sa\", 0.6000496745109558), (\"kid'sa\", 0.5985488891601562), ('landing_Kolodjay', 0.5948057174682617)]\n",
      "==========\n",
      "[['taxi'], ['railway', 'station'], ['door'], ['speed'], ['road'], ['time']]\n",
      "2 [('highway', 0.5822356939315796), ('bus', 0.56187504529953), ('motorway', 0.5585417747497559), ('mainline_railway', 0.5583980083465576), ('train', 0.5575571656227112)]\n",
      "==========\n",
      "[['judy']]\n",
      "3 [('leonard', 0.5828719735145569), ('baxter', 0.575350284576416), ('ricky', 0.5736008882522583), ('bryan', 0.5715378522872925), ('felix', 0.5693106055259705)]\n",
      "==========\n",
      "[['student', 'cambridge', 'university', 'read', 'something', 'room'], ['bedroom', 'drawing', 'room', 'wood'], ['bathroom'], ['daughter', 'year'], ['afternoon', 'smith'], ['room', 'window', 'scene', 'bird'], ['something', 'room'], ['move']]\n",
      "4 [('upstairs', 0.604987382888794), ('downstairs', 0.6036388874053955), ('vomiting_Jean_Baptiste', 0.5993413329124451), ('rouse_Koppel', 0.5870085954666138), ('sunporch', 0.5857304334640503)]\n",
      "==========\n",
      "[['allison'], ['moment'], ['hour'], ['message'], ['chris'], ['number'], ['thank', 'someone', 'door']]\n",
      "5 [('leannrimes_@', 0.6202532052993774), (\"Sorry_ma'am\", 0.6150302886962891), ('@_kiranchetrycnn_@', 0.6118425130844116), ('THE_PRESIDENT_Yes', 0.6095706224441528), ('jennajameson_@', 0.601901113986969)]\n",
      "==========\n",
      "[['taxi'], ['wangfujing'], ['music', 'radio'], ['program', 'driving', 'what', 'program'], ['winner', 'mush', 'know', 'beijing', 'game', 'corner', 'well', 'china', 'business', 'radio', 'radio'], ['english'], ['program', 'beginner'], ['morning', 'minute'], ['radio', 'lot', 'convenience'], ['traffic', 'condition'], ['development', 'society', 'technology', 'radio'], ['advantage']]\n",
      "6 [('Komando_hosts_national', 0.6470147371292114), ('BY_CHERYL_LAVIN_cheryllavin@aol.com', 0.614291787147522), ('Laura_Schlessinger_shifts', 0.6116952300071716), ('%_#F########_3v.jsn', 0.610867977142334), ('Logue_typed', 0.6099706292152405)]\n",
      "==========\n",
      "[['wonder', 'change', 'channel'], ['what', 'channel'], ['football', 'match'], ['play', 'football'], ['radio']]\n",
      "7 [('RAFAEL_NADAL_Yeah', 0.5821092128753662), ('game', 0.5757821798324585), ('misspell_Murkowski', 0.5495395660400391), ('Berezovsky_Valery_Dyatlenko', 0.5468813180923462), ('fooball', 0.546824038028717)]\n",
      "==========\n",
      "[['excuse', 'show', 'cloisonn', 'bracelet', 'counter'], ['problem', 'gold'], ['cloisonn', 'bracelet'], ['luster', 'fade', 'time'], ['quality']]\n",
      "8 [('Nastia_deserved', 0.5396358370780945), ('Oludamola_stripped', 0.531161904335022), ('Cuba_Yumileidi_Cumba_Jay', 0.5196471214294434), ('%_#F########_7v.jsn', 0.5129485726356506), ('ANo', 0.5101053714752197)]\n",
      "==========\n",
      "[['anything', 'channel'], ['basketball', 'match', 'channel'], ['mind'], ['movie'], ['what', 'movie'], ['star']]\n",
      "9 [('Crave_Online_Did', 0.5898535251617432), ('ANDY_RODDICK_Yeah', 0.5890165567398071), ('MediaBlvd_How', 0.5840082168579102), ('RAFAEL_NADAL_Yeah', 0.5839110016822815), ('MovieRetriever', 0.577406644821167)]\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "for i,dlg in enumerate(longer_dialogs_nlpd_cleaned_2[:10]):\n",
    "    lst = list(itertools.chain.from_iterable(dlg))\n",
    "    lst = [w for w in lst if w in word_vectors.vocab]\n",
    "    wvtop = word_vectors.most_similar(positive=lst)\n",
    "    print(dlg)\n",
    "    print(i,wvtop[:5])\n",
    "    print('='*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('wine_spritzer', 0.706296443939209),\n",
       " ('unsweetened_iced_tea', 0.687741219997406),\n",
       " ('unsweet_tea', 0.6812054514884949),\n",
       " ('triple_sec', 0.6755117177963257),\n",
       " ('drinks', 0.6749691963195801),\n",
       " ('Caipirinhas', 0.670561671257019),\n",
       " ('gin_martini', 0.6701815724372864),\n",
       " ('fizzy_citrus', 0.6674100160598755),\n",
       " ('glassful', 0.6648150682449341),\n",
       " ('martini', 0.6612378358840942)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar(positive=list(itertools.chain.from_iterable(longer_dialogs_nlpd_cleaned[501])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Believe it or not , tea is the most popular beverage in the world after water . ',\n",
       " ' Well , people from Asia to Europe all enjoy tea . ',\n",
       " ' Right . And China is the homeland of tea . ',\n",
       " \" Yes , Chinese people love drinking tea so much . Some even claim they can't live without tea . \",\n",
       " ' Do you know there are several catagories of Chinese tea ? ',\n",
       " ' Yes , I believe there are green teas , black teas and scented teas . Any Others ? ',\n",
       " ' Well , have you ever heard of Oulong tea and compressed tea ? ',\n",
       " \" Oh , yeah . Oulong tea is good for one's health . isn't it ? \",\n",
       " ' You surely know a lot about Chinese tea . ',\n",
       " ' Sure , I like drinking tea at teahouses . ',\n",
       " ' Oh , so do I . ',\n",
       " \" Why don't we go for one now ? \",\n",
       " ' Great . We can chat while enjoying a cup there . ',\n",
       " \" Let's go ! \",\n",
       " '']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longer_dialogs[512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "kys = list(itertools.chain.from_iterable(longer_dialogs_nlpd_cleaned[512]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [(k in word_vectors.vocab) for k in kys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('shape_Angius', 0.687379002571106),\n",
       " ('THC_infused_lozenges', 0.5973172187805176),\n",
       " ('pancakes_sausage_orange_juice', 0.570042610168457),\n",
       " ('Wolfgang_Puck_gourmet', 0.5698696970939636),\n",
       " ('UDBKL', 0.5656538009643555),\n",
       " ('juice_Leclerc', 0.5617351531982422),\n",
       " ('coffee', 0.5509310364723206),\n",
       " ('CDMHY', 0.5456836223602295),\n",
       " ('decaffeinated_brew', 0.5453557968139648),\n",
       " ('KF_OOE', 0.5437560081481934)]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import compress\n",
    "word_vectors.most_similar(positive=list(compress(kys, lst)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Puccini_opera', 0.5856292843818665),\n",
       " ('Andrei_Serban', 0.5844423770904541),\n",
       " ('operas', 0.5825181007385254),\n",
       " ('Janacek_opera', 0.581346869468689),\n",
       " ('Giacomo_Puccini_La_Boheme', 0.5792374610900879),\n",
       " ('operatic', 0.572944164276123),\n",
       " ('Mozart_Magic_Flute', 0.5718279480934143),\n",
       " ('ensemble', 0.5713194608688354),\n",
       " ('Die_Meistersinger_von_NÃ¼rnberg', 0.570805549621582),\n",
       " ('Threepenny', 0.5686825513839722)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar(positive=['story','plot','orchestra','opera','cast','television'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Freely_indulging', 0.525499165058136),\n",
       " ('play', 0.5145164728164673),\n",
       " ('creator_Peter_Molyneux', 0.5130865573883057),\n",
       " ('Dracula_castle', 0.5099152326583862),\n",
       " ('tale_Mr._Magorium', 0.5076123476028442),\n",
       " ('Far_Cry_Vengeance', 0.49884775280952454),\n",
       " ('comedy_Tooth_Fairy', 0.4976005554199219),\n",
       " ('Aragorn_Quest', 0.496908038854599),\n",
       " ('storyline', 0.4931725859642029),\n",
       " ('ChuChu_Rocket', 0.4905066192150116)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar(positive=['game','games','castle','king','story','plot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('buildings', 0.6392232775688171),\n",
       " ('adaptively_reuse', 0.6207095980644226),\n",
       " ('nonhistoric', 0.5787556767463684),\n",
       " ('adaptively_reused', 0.575765073299408),\n",
       " ('Historic', 0.5745522975921631),\n",
       " ('Exterior_renovations', 0.5649078488349915),\n",
       " ('Building', 0.5599408745765686),\n",
       " ('authentically_restored', 0.5566396713256836),\n",
       " ('Classical_Revival', 0.5519300699234009),\n",
       " ('landmark', 0.5515885949134827)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar(positive=['historic', 'building'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
